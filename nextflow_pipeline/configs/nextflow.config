profiles {
    // Nextflow configuration file for local execution
    local {
        docker.enabled = false
        conda.enabled = true
        dag.enabled = true
        executor {
            name = 'local'
        }
        params {
            // Define any parameters you want to use in your pipeline
            segmentation_env = '~/miniforge3/envs/GFF_segmentation'
            featurization_env = '~/miniforge3/envs/GFF_featurization'
        }


    }

    SLURM_HPC {
        // Nextflow configuration file for HPC
        // This file is used to configure the Nextflow pipeline for running on a Slurm HPC cluster.
        docker.enabled = false
        conda.enabled = true
        dag.enabled = true

        executor {
            name = 'slurm'
            queueSize = 100 // Number of jobs to be queued at one time
        }
        params {
            // Define any parameters you want to use in your pipeline
            segmentation_env = '/projects/mlippincott@xsede.org/software/anaconda/envs/GFF_segmentation'
            featurization_env = '/projects/mlippincott@xsede.org/software/anaconda/envs/GFF_featurization'
        }

        process {

            withName:SEGMENTATION {
                // Define the resources for the segmentation process
                executor = 'slurm'
                time = '1h'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                maxRetries = 2 // number of retries
                queue = 'aa100' // this is the partition
                clusterOptions = '--gres=gpu:1 --account=amc-general --ntasks=6 --qos=normal --output=segmentation_child-%j.out'
                maxForks = 2  // ← Only 2 segmentation jobs run at a time
            }
            withName:SEGMENTATION_CLEANUP {
                // Define the resources for the SEGMENTATION_CLEANUP process
                executor = 'slurm'
                time = '1h'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                queue = 'amilan' // this is the partition
                clusterOptions = '--account=amc-general --ntasks=1 --qos=normal --output=SEGMENTATION_CLEANUP_child-%j.out'
                maxForks = 2  // ← Only 2 SEGMENTATION_CLEANUP jobs run at a time
            }
            withTag:areasizeshape_cpu {
                // Define the resources for the areasizeshape_cpu process
                executor = 'slurm'
                time = '10m'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                queue = 'amilan' // this is the partition
                clusterOptions = '--account=amc-general --ntasks=2 --qos=normal --output=areasizeshape_cpu_child-%j.out'
                maxForks = 2  // ← Only 2 areasizeshape_cpu jobs run at a time
            }
            withTag:areasizeshape_gpu {
                // Define the resources for the areasizeshape_gpu process
                executor = 'slurm'
                time = '10m'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                queue = 'aa100' // this is the partition
                clusterOptions = '--gres=gpu:1 --account=amc-general --ntasks=1 --qos=normal --output=areasizeshape_gpu_child-%j.out'
                maxForks = 2  // ← Only 2 areasizeshape_gpu jobs run at a time
            }
            withTag:colocalization_cpu {
                // Define the resources for the colocalization_cpu process
                executor = 'slurm'
                time = '1h'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                queue = 'amilan' // this is the partition
                clusterOptions = '--account=amc-general --ntasks=20 --qos=normal --output=colocalization_cpu_child-%j.out'
                maxForks = 2  // ← Only 2 colocalization_cpu jobs run at a time
            }
            withTag:colocalization_gpu {
                // Define the resources for the colocalization_gpu process
                executor = 'slurm'
                time = '1h'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                queue = 'aa100' // this is the partition
                clusterOptions = '--gres=gpu:1 --account=amc-general --ntasks=2 --qos=normal --output=colocalization_gpu_child-%j.out'
                maxForks = 2  // ← Only 2 colocalization_gpu jobs run at a time
            }
            withTag:granularity_cpu {
                // Define the resources for the granularity_cpu process
                executor = 'slurm'
                time = '4h'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                queue = 'amilan' // this is the partition
                clusterOptions = '--account=amc-general --ntasks=20 --qos=normal --output=granularity_cpu_child-%j.out'
                maxForks = 2  // ← Only 2 granularity_cpu jobs run at a time
            }
            withTag:granularity_gpu {
                // Define the resources for the granularity_gpu process
                executor = 'slurm'
                time = '2h'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                queue = 'aa100' // this is the partition
                clusterOptions = '--gres=gpu:1 --account=amc-general --ntasks=2 --qos=normal --output=granularity_gpu_child-%j.out'
                maxForks = 2  // ← Only 2 granularity_gpu jobs run at a time
            }
            withTag:intensity_cpu {
                // Define the resources for the intensity_cpu process
                executor = 'slurm'
                time = '6h'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                queue = 'amilan' // this is the partition
                clusterOptions = '--account=amc-general --ntasks=20 --qos=normal --output=intensity_cpu_child-%j.out'
                maxForks = 2  // ← Only 2 intensity_cpu jobs run at a time
            }
            withTag:intensity_gpu {
                // Define the resources for the intensity_gpu process
                executor = 'slurm'
                time = '3h'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                queue = 'aa100' // this is the partition
                clusterOptions = '--gres=gpu:1 --account=amc-general --ntasks=2 --qos=normal --output=intensity_gpu_child-%j.out'
                maxForks = 2  // ← Only 2 intensity_gpu jobs run at a time
            }
            withTag:neighbors_cpu {
                // Define the resources for the neighbors_cpu process
                executor = 'slurm'
                time = '10m'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                queue = 'amilan' // this is the partition
                clusterOptions = '--account=amc-general --ntasks=1 --qos=normal --output=neighbors_cpu_child-%j.out'
                maxForks = 2  // ← Only 2 neighbors_cpu jobs run at a time
            }
            withTag:texture_cpu {
                // Define the resources for the texture_cpu process
                executor = 'slurm'
                time = '16h'
                errorStrategy = 'terminate' // options: retry, ignore, finish, terminate
                queue = 'amilan' // this is the partition
                clusterOptions = '--account=amc-general --ntasks=20 --qos=normal --output=texture_cpu_child-%j.out'
                maxForks = 2  // ← Only 2 texture_cpu jobs run at a time
            }
        }
    }
}
