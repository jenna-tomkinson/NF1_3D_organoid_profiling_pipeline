{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to correct potential errors in the segmentation of the 3D image data.\n",
    "Potential errors can be observed in the figure below where each row is a different slice of the 3D image data and each column is a different outcome of the segmentation.\n",
    "Each segmentation of cell and nucleus is shown in a different color.\n",
    "Where cells or nuclei that are the same object id are shown in the same color.\n",
    "While cells and nuclei that are different object ids are shown in different colors.\n",
    "Some of the outcomes are not correct and need to be corrected.\n",
    "While others might be correct or incorrect but there is not logical way to determine if they are correct or not. \n",
    "These cases are not corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pathlib\n",
    "import sys\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import tifffile\n",
    "\n",
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "if (cwd / \".git\").is_dir():\n",
    "    root_dir = cwd\n",
    "else:\n",
    "    root_dir = None\n",
    "    for parent in cwd.parents:\n",
    "        if (parent / \".git\").is_dir():\n",
    "            root_dir = parent\n",
    "            break\n",
    "sys.path.append(str(root_dir / \"utils\"))\n",
    "from arg_parsing_utils import check_for_missing_args, parse_args\n",
    "from notebook_init_utils import bandicoot_check, init_notebook\n",
    "\n",
    "root_dir, in_notebook = init_notebook()\n",
    "\n",
    "image_base_dir = bandicoot_check(pathlib.Path(\"~/mnt/bandicoot\").resolve(), root_dir)\n",
    "\n",
    "from segmentation_decoupling import euclidian_2D_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in a notebook\n"
     ]
    }
   ],
   "source": [
    "if not in_notebook:\n",
    "    args = parse_args()\n",
    "    compartment = args[\"compartment\"]\n",
    "    well_fov = args[\"well_fov\"]\n",
    "    patient = args[\"patient\"]\n",
    "    check_for_missing_args(\n",
    "        well_fov=well_fov,\n",
    "        patient=patient,\n",
    "        compartment=compartment,\n",
    "    )\n",
    "else:\n",
    "    print(\"Running in a notebook\")\n",
    "    well_fov = \"G9-2\"\n",
    "    compartment = \"organoid\"\n",
    "    patient = \"NF0014_T1\"\n",
    "\n",
    "mask_dir = pathlib.Path(\n",
    "    f\"{image_base_dir}/data/{patient}/segmentation_masks/{well_fov}\"\n",
    ").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compartment == \"nuclei\":\n",
    "    mask_path = mask_dir / \"nuclei_masks_reconstructed.tiff\"\n",
    "    mask_output_path = mask_dir / \"nuclei_masks_reconstructed_corrected.tiff\"\n",
    "elif compartment == \"cell\":\n",
    "    mask_path = mask_dir / \"cell_masks_watershed.tiff\"\n",
    "    mask_output_path = mask_dir / \"cell_masks_corrected.tiff\"\n",
    "elif compartment == \"organoid\":\n",
    "    mask_path = mask_dir / \"organoid_masks_reconstructed.tiff\"\n",
    "    mask_output_path = mask_dir / \"organoid_masks_reconstructed_corrected.tiff\"\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Compartment must be either nuclei, cell or organoid\")\n",
    "\n",
    "mask = tifffile.imread(mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bbox_area(bbox: Tuple[int, int, int, int]) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the area of a bounding box.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bbox : Tuple[int, int, int, int]\n",
    "        The bounding box coordinates in the format (x_min, y_min, x_max, y_max).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The area of the bounding box.\n",
    "    \"\"\"\n",
    "    return (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "\n",
    "\n",
    "def calculate_overlap(\n",
    "    bbox1: Tuple[int, int, int, int], bbox2: Tuple[int, int, int, int]\n",
    ") -> float:\n",
    "    # calculate the % overlap of the second bbox with the first bbox\n",
    "    if calculate_bbox_area(bbox1) == 0 or calculate_bbox_area(bbox2) == 0:\n",
    "        return 0.0\n",
    "    if calculate_bbox_area(bbox1) >= calculate_bbox_area(bbox2):\n",
    "        x_min = max(bbox1[0], bbox2[0])\n",
    "        y_min = max(bbox1[1], bbox2[1])\n",
    "        x_max = min(bbox1[2], bbox2[2])\n",
    "        y_max = min(bbox1[3], bbox2[3])\n",
    "        overlap_width = max(0, x_max - x_min)\n",
    "        overlap_height = max(0, y_max - y_min)\n",
    "        overlap_area = overlap_width * overlap_height\n",
    "        bbox1_area = calculate_bbox_area(bbox1)\n",
    "        bbox2_area = calculate_bbox_area(bbox2)\n",
    "        overlap_percentage = overlap_area / bbox2_area if bbox2_area > 0 else 0\n",
    "        return overlap_percentage\n",
    "    elif calculate_bbox_area(bbox1) < calculate_bbox_area(bbox2):\n",
    "        x_min = max(bbox1[0], bbox2[0])\n",
    "        y_min = max(bbox1[1], bbox2[1])\n",
    "        x_max = min(bbox1[2], bbox2[2])\n",
    "        y_max = min(bbox1[3], bbox2[3])\n",
    "        overlap_width = max(0, x_max - x_min)\n",
    "        overlap_height = max(0, y_max - y_min)\n",
    "        overlap_area = overlap_width * overlap_height\n",
    "        bbox1_area = calculate_bbox_area(bbox1)\n",
    "        bbox2_area = calculate_bbox_area(bbox2)\n",
    "        overlap_percentage = overlap_area / bbox1_area if bbox1_area > 0 else 0\n",
    "        return overlap_percentage\n",
    "    else:\n",
    "        print(\"Error: Bboxes are the same size\")\n",
    "\n",
    "\n",
    "def merge_sets(list_of_sets: list) -> list:\n",
    "    \"\"\"\n",
    "    Merge sets in a list of sets if they have any intersection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_sets : list\n",
    "        A list of sets to be merged.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of sets after merging those that intersect.\n",
    "    \"\"\"\n",
    "    for i, set1 in enumerate(list_of_sets):\n",
    "        for j, set2 in enumerate(list_of_sets):\n",
    "            if i != j and len(set1.intersection(set2)) > 0:\n",
    "                set1.update(set2)\n",
    "    return list_of_sets\n",
    "\n",
    "\n",
    "def check_for_all_same_labels(\n",
    "    object_information_df: pd.DataFrame,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Check if all labels in the object information DataFrame are the same.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    object_information_df : pd.DataFrame\n",
    "        The DataFrame containing object information with 'label' column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if all labels are the same, False otherwise.\n",
    "    \"\"\"\n",
    "    return object_information_df[\"label\"].nunique() == 1\n",
    "\n",
    "\n",
    "def missing_slice_check(\n",
    "    object_information_df: pd.DataFrame,\n",
    "    window_min: int = 0,\n",
    "    window_max: int = 2,\n",
    "    interpolated_rows_to_add: List[int] = [],\n",
    ") -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Check for missing slices in the object information DataFrame and add interpolated rows if necessary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    object_information_df : pd.DataFrame\n",
    "        The DataFrame containing object information with 'z' and 'label' columns.\n",
    "    window_min : int, optional\n",
    "        The minimum window size for checking missing slices, by default 0\n",
    "    window_max : int, optional\n",
    "        The maximum window size for checking missing slices, by default 2\n",
    "    interpolated_rows_to_add : List[int], optional\n",
    "        A list to store rows to be added for interpolation, by default []\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[pd.DataFrame]\n",
    "        A list of DataFrames containing rows to be added for interpolation.\n",
    "    \"\"\"\n",
    "    max_z = object_information_df[\"z\"].max()\n",
    "    min_z = object_information_df[\"z\"].min()\n",
    "    if max_z - min_z > 1:\n",
    "        if len(object_information_df) < 3:\n",
    "            # get the first row\n",
    "            row = object_information_df.iloc[0]\n",
    "            new_row = {\n",
    "                \"added_z\": row[\"z\"],\n",
    "                \"added_new_label\": row[\"label\"],\n",
    "                \"zslice_to_copy\": row[\"z\"],\n",
    "            }\n",
    "\n",
    "            # interpolate the labels to the middle most slice\n",
    "            # get the middle slice\n",
    "            middle_slice = int((max_z + min_z) / 2)\n",
    "            # insert one slice\n",
    "            z_zlice_to_copy = row[\"z\"]\n",
    "\n",
    "            new_row = {\n",
    "                # 'index': object_information_df['index'].values[0],\n",
    "                # 'index': object_max_slice_label,\n",
    "                \"added_z\": middle_slice,\n",
    "                \"added_new_label\": row[\"label\"],\n",
    "                \"zslice_to_copy\": z_zlice_to_copy,\n",
    "            }\n",
    "            interpolated_rows_to_add.append(pd.DataFrame(new_row, index=[0]))\n",
    "    return interpolated_rows_to_add\n",
    "\n",
    "\n",
    "def add_min_max_boundry_slices(\n",
    "    object_information_df: pd.DataFrame,\n",
    "    global_min_z: int,\n",
    "    global_max_z: int,\n",
    "    interpolated_rows_to_add: List[pd.DataFrame] = [],\n",
    ") -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Add slices to the object information DataFrame that are one slice away from the global min and max z slices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    object_information_df : pd.DataFrame\n",
    "        The DataFrame containing object information with 'z' and 'label' columns.\n",
    "    global_min_z : int\n",
    "        The global minimum z slice.\n",
    "    global_max_z : int\n",
    "        The global maximum z slice.\n",
    "    interpolated_rows_to_add : List[pd.DataFrame], optional\n",
    "        A list to store rows to be added for interpolation, by default []\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[pd.DataFrame]\n",
    "        A list of DataFrames containing rows to be added for interpolation at the min and max z slices.\n",
    "    \"\"\"\n",
    "    # find labels that are 1 slice away from the min or max and extend the label\n",
    "    for i, row in object_information_df.iterrows():\n",
    "        # check if the z slice is one away from the min or max (global min and max)\n",
    "        if row[\"z\"] == global_max_z - 1:\n",
    "            new_row = {\n",
    "                \"added_z\": global_max_z,\n",
    "                \"added_new_label\": row[\"label\"],\n",
    "                \"zslice_to_copy\": row[\"z\"],\n",
    "            }\n",
    "            interpolated_rows_to_add.append(pd.DataFrame(new_row, index=[0]))\n",
    "        elif row[\"z\"] == global_min_z + 1:\n",
    "            new_row = {\n",
    "                \"added_z\": global_min_z,\n",
    "                \"added_new_label\": row[\"label\"],\n",
    "                \"zslice_to_copy\": row[\"z\"],\n",
    "            }\n",
    "            interpolated_rows_to_add.append(pd.DataFrame(new_row, index=[0]))\n",
    "    return interpolated_rows_to_add\n",
    "\n",
    "\n",
    "def add_masks_where_missing(\n",
    "    new_mask_image: np.ndarray,\n",
    "    interpolated_rows_to_add_df: pd.DataFrame,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Add masks to the new mask image where the slices are missing based on the interpolated rows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    new_mask_image : np.ndarray\n",
    "        The new mask image to which the slices will be added.\n",
    "    interpolated_rows_to_add_df : pd.DataFrame\n",
    "        The DataFrame containing the rows to be added for interpolation, with columns 'added_z', 'added_new_label', and 'zslice_to_copy'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The new mask image with the added slices.\n",
    "    \"\"\"\n",
    "    for slice in interpolated_rows_to_add_df[\"added_z\"].unique():\n",
    "        # get the rows that correspond to the slice\n",
    "        tmp_df = interpolated_rows_to_add_df[\n",
    "            interpolated_rows_to_add_df[\"added_z\"] == slice\n",
    "        ]\n",
    "        if tmp_df.shape[0] == 0:\n",
    "            continue\n",
    "        for i, row in tmp_df.iterrows():\n",
    "            # get the z slice to copy mask\n",
    "            new_slice = new_mask_image[row[\"zslice_to_copy\"].astype(int), :, :].copy()\n",
    "            new_slice[new_slice != row[\"added_new_label\"]] = 0\n",
    "\n",
    "            old_slice = new_mask_image[row[\"added_z\"].astype(int), :, :].copy()\n",
    "            max_projected_slice = np.maximum(old_slice, new_slice)\n",
    "            new_mask_image[row[\"added_z\"].astype(int), :, :] = max_projected_slice\n",
    "    return new_mask_image\n",
    "\n",
    "\n",
    "def reorder_organoid_labels(\n",
    "    label_image: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reorder the labels in the label image to ensure they are sequential starting from 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label_image : np.ndarray\n",
    "        The label image where labels need to be reordered.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The label image with reordered labels.\n",
    "    \"\"\"\n",
    "    unique_labels = np.unique(label_image)\n",
    "    # remove the background label (0)\n",
    "    unique_labels = unique_labels[unique_labels != 0]\n",
    "    # exit early if there are no labels (only background)\n",
    "    if len(unique_labels) == 0:\n",
    "        return label_image\n",
    "    # create a mapping from old label to new label\n",
    "    label_mapping = {\n",
    "        old_label: new_label\n",
    "        for new_label, old_label in enumerate(unique_labels, start=1)\n",
    "    }\n",
    "    label_image_corrected = np.copy(label_image)\n",
    "    for old_label, new_label in label_mapping.items():\n",
    "        label_image_corrected[label_image == old_label] = new_label\n",
    "    return label_image_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data flow objects, constants and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window_context = 3\n",
    "global_max_z = mask.shape[0]  # number of z slices\n",
    "global_min_z = 0\n",
    "# expand the z slices into a list  of slices between the min and max z slices\n",
    "z_slices = [x for x in range(global_min_z, global_max_z)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through the slices in a sliding window fashion and correct the segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask_image = mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in z_slices[: -(sliding_window_context - 1)]:\n",
    "    interpolated_rows_to_add = []\n",
    "\n",
    "    final_dict = {\n",
    "        \"index1\": [],\n",
    "        \"index2\": [],\n",
    "        \"z1\": [],\n",
    "        \"z2\": [],\n",
    "        \"distance\": [],\n",
    "        \"label1\": [],\n",
    "        \"label2\": [],\n",
    "    }\n",
    "    list_of_cell_masks = []\n",
    "    for z_slice in range(0, new_mask_image.shape[0] - 1):\n",
    "        compartment_df = pd.DataFrame.from_dict(\n",
    "            skimage.measure.regionprops_table(\n",
    "                new_mask_image[z, :, :],\n",
    "                properties=[\"centroid\", \"bbox\"],\n",
    "            )\n",
    "        )\n",
    "        compartment_df[\"z\"] = z_slice\n",
    "\n",
    "        list_of_cell_masks.append(compartment_df)\n",
    "    compartment_df = pd.concat(list_of_cell_masks)\n",
    "\n",
    "    # get the pixel value of the organoid mask at each x,y,z coordinate\n",
    "    compartment_df[\"label\"] = new_mask_image[\n",
    "        compartment_df[\"z\"].astype(int),\n",
    "        compartment_df[\"centroid-0\"].astype(int),\n",
    "        compartment_df[\"centroid-1\"].astype(int),\n",
    "    ]\n",
    "    compartment_df.reset_index(drop=True, inplace=True)\n",
    "    compartment_df[\"new_label\"] = compartment_df[\"label\"]\n",
    "    # drop all labels that are 0\n",
    "    compartment_df = compartment_df[compartment_df[\"label\"] != 0]\n",
    "\n",
    "    # Get the temporary sliding window\n",
    "    tmp_window_df = compartment_df[\n",
    "        (compartment_df[\"z\"] >= z) & (compartment_df[\"z\"] < z + sliding_window_context)\n",
    "    ]\n",
    "\n",
    "    if tmp_window_df[\"z\"].nunique() < sliding_window_context:\n",
    "        continue\n",
    "    for i, row1 in tmp_window_df.iterrows():\n",
    "        for j, row2 in tmp_window_df.iterrows():\n",
    "            if i != j:  # Ensure you're not comparing the same row\n",
    "                if row1[\"z\"] != row2[\"z\"]:\n",
    "                    # get the first bbox\n",
    "\n",
    "                    distance = euclidian_2D_distance(\n",
    "                        (row1[\"centroid-0\"], row1[\"centroid-1\"]),\n",
    "                        (row2[\"centroid-0\"], row2[\"centroid-1\"]),\n",
    "                    )\n",
    "\n",
    "                    if distance < 20:\n",
    "                        final_dict[\"index1\"].append(i)\n",
    "                        final_dict[\"index2\"].append(j)\n",
    "                        final_dict[\"z1\"].append(row1[\"z\"])\n",
    "                        final_dict[\"z2\"].append(row2[\"z\"])\n",
    "                        final_dict[\"distance\"].append(distance)\n",
    "                        final_dict[\"label1\"].append(row1[\"label\"])\n",
    "                        final_dict[\"label2\"].append(row2[\"label\"])\n",
    "    final_df = pd.DataFrame.from_dict(final_dict)\n",
    "    final_df[\"index_set\"] = final_df.apply(\n",
    "        lambda row: frozenset([row[\"index1\"], row[\"index2\"]]), axis=1\n",
    "    )\n",
    "    final_df[\"index_set\"] = final_df[\"index_set\"].apply(lambda x: tuple(sorted(x)))\n",
    "\n",
    "    list_of_sets = final_df[\"index_set\"].tolist()\n",
    "    list_of_sets = [set(s) for s in list_of_sets]\n",
    "    merged_sets = merge_sets(list_of_sets)\n",
    "    # drop the duplicates\n",
    "    merged_sets = list({frozenset(s): s for s in merged_sets}.values())\n",
    "\n",
    "    # from final_df generate the z-ordered cases\n",
    "    for object_set in merged_sets:\n",
    "        # find rows that contain integers that are in the object_set\n",
    "        rows_that_contain_object_set = final_df[\n",
    "            final_df[\"index_set\"].apply(lambda x: set(x).issubset(object_set))\n",
    "        ]\n",
    "        # get the index, label, and z pair\n",
    "        dict_of_object_information = {\"index\": [], \"label\": [], \"z\": []}\n",
    "        for i, row in rows_that_contain_object_set.iterrows():\n",
    "            dict_of_object_information[\"index\"].append(row[\"index1\"])\n",
    "            dict_of_object_information[\"label\"].append(row[\"label1\"])\n",
    "            dict_of_object_information[\"z\"].append(row[\"z1\"])\n",
    "            dict_of_object_information[\"index\"].append(row[\"index2\"])\n",
    "            dict_of_object_information[\"label\"].append(row[\"label2\"])\n",
    "            dict_of_object_information[\"z\"].append(row[\"z2\"])\n",
    "        object_information_df = pd.DataFrame.from_dict(dict_of_object_information)\n",
    "        object_information_df.drop_duplicates(\n",
    "            subset=[\"index\", \"label\", \"z\"], inplace=True\n",
    "        )\n",
    "        object_information_df.sort_values(by=[\"index\", \"z\"], inplace=True)\n",
    "        if check_for_all_same_labels(object_information_df):\n",
    "            # if all labels are the same, skip this object\n",
    "            continue\n",
    "        interpolated_rows_to_add = missing_slice_check(\n",
    "            object_information_df, interpolated_rows_to_add=interpolated_rows_to_add\n",
    "        )\n",
    "        interpolated_rows_to_add = add_min_max_boundry_slices(\n",
    "            object_information_df,\n",
    "            global_min_z=global_min_z,\n",
    "            global_max_z=global_max_z,\n",
    "            interpolated_rows_to_add=interpolated_rows_to_add,\n",
    "        )\n",
    "\n",
    "    if len(interpolated_rows_to_add) == 0:\n",
    "        if z == z_slices[-1]:\n",
    "            tifffile.imwrite(mask_output_path, new_mask_image)\n",
    "        else:\n",
    "            continue\n",
    "    interpolated_rows_to_add_df = pd.concat(interpolated_rows_to_add, axis=0)\n",
    "    new_mask_image = new_mask_image.copy()\n",
    "    new_mask_image = add_masks_where_missing(\n",
    "        new_mask_image=new_mask_image,\n",
    "        interpolated_rows_to_add_df=interpolated_rows_to_add_df,\n",
    "    )\n",
    "    print(\"writing the mask for z slice\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the organoid labels\n",
    "new_mask_image = reorder_organoid_labels(new_mask_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not mask_output_path.exists():\n",
    "    tifffile.imwrite(mask_output_path, new_mask_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GFF_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
