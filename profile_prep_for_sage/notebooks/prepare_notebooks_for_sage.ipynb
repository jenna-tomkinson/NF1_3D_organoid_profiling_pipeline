{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b054297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import synapseclient\n",
    "import synapseutils\n",
    "\n",
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "if (cwd / \".git\").is_dir():\n",
    "    root_dir = cwd\n",
    "else:\n",
    "    root_dir = None\n",
    "    for parent in cwd.parents:\n",
    "        if (parent / \".git\").is_dir():\n",
    "            root_dir = parent\n",
    "            break\n",
    "sys.path.append(str(root_dir / \"utils\"))\n",
    "from notebook_init_utils import bandicoot_check, init_notebook\n",
    "\n",
    "root_dir, in_notebook = init_notebook()\n",
    "if in_notebook:\n",
    "    import tqdm.notebook as tqdm\n",
    "else:\n",
    "    import tqdm\n",
    "profile_base_dir = bandicoot_check(\n",
    "    pathlib.Path(os.path.expanduser(\"~/mnt/bandicoot\")).resolve(), root_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd6b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_remove_empty_dirs(path: pathlib.Path):\n",
    "    \"\"\"\n",
    "    Recursively remove empty directories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : pathlib.Path\n",
    "        The root directory to start removing empty directories from.\n",
    "    \"\"\"\n",
    "    if not path.is_dir():\n",
    "        return\n",
    "    for child in path.iterdir():\n",
    "        recursive_remove_empty_dirs(child)\n",
    "    if not any(path.iterdir()):\n",
    "        path.rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dir = pathlib.Path(f\"{profile_base_dir}/data/all_patient_profiles\").resolve()\n",
    "# get all patient profile dirs\n",
    "profile_dirs = [\n",
    "    d for d in profiles_dir.rglob(\"*.parquet\") if \"featurization\" not in str(d)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a4c6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_profiles_dir = pathlib.Path(\n",
    "    \"../data_for_sage/Raw Data/bulk quantification/\"\n",
    "    # see comments below if the spaces in the path annoy you...\n",
    "    # to match the expected input dir for sage\n",
    "    # note, the data_for_sage part of the dir does not get synced to synapse\n",
    "    # this path provided syncs everything that matches ( or not ) a pattern\n",
    "    # on synapse\n",
    "    # so we need to make sure the directory structure is correct\n",
    "    # also, this directory should be temporary and not checked into git\n",
    "    # so it is in the .gitignore file just in case\n",
    "    # but is also deleted at the end of this notebook\n",
    ").resolve()\n",
    "if sage_profiles_dir.exists():\n",
    "    shutil.rmtree(sage_profiles_dir)\n",
    "sage_profiles_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58360ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b396d40133e480ca8268d47279c00e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get each of the profiles and split them by:\n",
    "# patient tumor, treatment, dose+units\n",
    "for profile_file_path in tqdm.tqdm(profile_dirs):\n",
    "    profile_name = profile_file_path.stem.split(\"_profiles\")[0]\n",
    "    profile_name = profile_name.replace(\"fs\", \"feature_selected\")\n",
    "    profile_name = profile_name.replace(\"agg\", \"aggregated\")\n",
    "    df = pd.read_parquet(profile_file_path)\n",
    "    df[\"Metadata_dose_plus_units\"] = (\n",
    "        df[\"Metadata_dose\"].astype(str) + \"_\" + df[\"Metadata_unit\"]\n",
    "    )\n",
    "    df.to_parquet(\n",
    "        f\"{sage_profiles_dir}/{profile_name}.parquet\",\n",
    "        partition_cols=[\n",
    "            \"Metadata_patient_tumor\",\n",
    "            \"Metadata_treatment\",\n",
    "            \"Metadata_dose_plus_units\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dirs = [d for d in sage_profiles_dir.glob(\"**/*\") if d.is_dir()]\n",
    "# get a list of all output files and dirs\n",
    "output_dirs = sorted(\n",
    "    [d for d in list(sage_profiles_dir.glob(\"**/*\")) if d.is_dir()],\n",
    "    key=lambda x: len(x.parts),\n",
    "    reverse=True,\n",
    ")\n",
    "# get a list of all output files and dirs\n",
    "output_dirs = [d for d in sage_profiles_dir.glob(\"**/*\") if d.is_dir()]\n",
    "# rename the most nested dirs first to avoid issues with parent dirs being renamed before child dirs\n",
    "_ = [\n",
    "    d.rename(d.parent / d.name.replace(\"=\", \"_\"))\n",
    "    for d in sorted(output_dirs, key=lambda x: len(x.parts), reverse=True)\n",
    "    if \"=\" in d.name\n",
    "]\n",
    "output_dirs = [d for d in sage_profiles_dir.glob(\"**/*\") if d.is_dir()]\n",
    "_ = [\n",
    "    d.rename(d.parent / d.name.replace(\"%\", \"percent\"))\n",
    "    for d in sorted(output_dirs, key=lambda x: len(x.parts), reverse=True)\n",
    "    if \"%\" in d.name\n",
    "]\n",
    "output_dirs = [d for d in sage_profiles_dir.glob(\"**/*\") if d.is_dir()]\n",
    "_ = [\n",
    "    shutil.rmtree(d)\n",
    "    for d in output_dirs\n",
    "    if \"Metadata_treatment___HIVE_DEFAULT_PARTITION__\" in d.name\n",
    "]\n",
    "output_dirs = [d for d in sage_profiles_dir.glob(\"**/*\") if d.is_dir()]\n",
    "# replace Metadata_patient_tumor_ with \"\"\n",
    "_ = [\n",
    "    d.rename(d.parent / d.name.replace(\"Metadata_patient_tumor_\", \"\"))\n",
    "    for d in output_dirs\n",
    "    if \"Metadata_patient_tumor_\" in d.name\n",
    "]\n",
    "output_dirs = [d for d in sage_profiles_dir.glob(\"**/*\") if d.is_dir()]\n",
    "# replace Metadata_treatment_ with \"\"\n",
    "_ = [\n",
    "    d.rename(d.parent / d.name.replace(\"Metadata_treatment_\", \"\"))\n",
    "    for d in output_dirs\n",
    "    if \"Metadata_treatment_\" in d.name\n",
    "]\n",
    "output_dirs = [d for d in sage_profiles_dir.glob(\"**/*\") if d.is_dir()]\n",
    "\n",
    "# replace Metadata_dose_plus_units_ with \"\"\n",
    "_ = [\n",
    "    d.rename(d.parent / d.name.replace(\"Metadata_dose_plus_units_\", \"\"))\n",
    "    for d in output_dirs\n",
    "    if \"Metadata_dose_plus_units_\" in d.name\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b6b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = [f for f in sage_profiles_dir.glob(\"**/*\") if f.is_file()]\n",
    "# loop through and rename files to contain the proper metadata\n",
    "for file in output_files:\n",
    "    parent_dir = str(file).split(\".parquet/\")[0]\n",
    "    new_file_name = (\n",
    "        str(file)\n",
    "        .split(\".parquet/\")[1]\n",
    "        .replace(\"/\", \"_\")\n",
    "        .replace(f\"{str(file.stem)}.\", \"\")\n",
    "    )\n",
    "    new_file_path = pathlib.Path(parent_dir) / new_file_name\n",
    "    new_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    file.rename(new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the empty dirs from where files used to persist\n",
    "recursive_remove_empty_dirs(sage_profiles_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dfa78fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/lippincm/Documents/GFF_3D_organoid_profiling_pipeline/profile_prep_for_sage/data_for_sage/Raw Data/bulk quantification/README.md')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "README_path = pathlib.Path(\"../README.md\").resolve()\n",
    "sage_readme_path = pathlib.Path(f\"{sage_profiles_dir}/README.md\").resolve()\n",
    "shutil.copy(README_path, sage_readme_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bda2d",
   "metadata": {},
   "source": [
    "## Upload the processed profiles to Synapse for Sage processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24793d75",
   "metadata": {},
   "source": [
    "Tutorial on how to use synapse client: https://python-docs.synapse.org/en/stable/tutorials/python/upload_data_in_bulk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ecc2f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, lippincm! You are using the 'default' profile.\n"
     ]
    }
   ],
   "source": [
    "# note, must run synapse config first in terminal to set up .synapseConfig file\n",
    "# or set some environment variables\n",
    "syn = synapseclient.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "926f5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project_id = my_project_id = syn.findEntityId(\n",
    "    name=\"A deep learning microscopy framework for NF1 patient-derived organoid drug screening\"\n",
    ")\n",
    "DIRECTORY_FOR_MY_PROJECT = os.path.join(\n",
    "    \"..\", \"data_for_sage/\"\n",
    ")  # tried using pathlib and it throws an error in the generate sync manifest function\n",
    "PATH_TO_MANIFEST_FILE = os.path.join(\".\", \"manifest-for-upload.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2090cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the manifest file to sync on\n",
    "synapseutils.generate_sync_manifest(\n",
    "    syn=syn,\n",
    "    directory_path=DIRECTORY_FOR_MY_PROJECT,\n",
    "    parent_id=my_project_id,\n",
    "    manifest_path=PATH_TO_MANIFEST_FILE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00714025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation and upload of: ./manifest-for-upload.tsv\n",
      "Validating columns of manifest...\n",
      "Validating that all paths exist...\n",
      "Validating that all files are unique...\n",
      "Validating that all the files are not empty...\n",
      "Validating file names...\n",
      "Validating provenance...\n",
      "Validating that parents exist and are containers...\n",
      "We are about to upload 1377 files with a total size of 1082316098.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading 1377 files: 100%|██████████| 1.08G/1.08G [04:56<00:00, 3.65MB/s]    \n"
     ]
    }
   ],
   "source": [
    "# sync the files to synapse\n",
    "synapseutils.syncToSynapse(\n",
    "    syn=syn, manifestFile=PATH_TO_MANIFEST_FILE, sendMessages=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GFF_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
