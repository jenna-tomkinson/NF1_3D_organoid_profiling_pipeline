{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62efb8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import umap\n",
    "\n",
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "if (cwd / \".git\").is_dir():\n",
    "    root_dir = cwd\n",
    "else:\n",
    "    root_dir = None\n",
    "    for parent in cwd.parents:\n",
    "        if (parent / \".git\").is_dir():\n",
    "            root_dir = parent\n",
    "            break\n",
    "sys.path.append(str(root_dir / \"utils\"))\n",
    "from notebook_init_utils import bandicoot_check, init_notebook\n",
    "\n",
    "root_dir, in_notebook = init_notebook()\n",
    "\n",
    "profile_base_dir = bandicoot_check(pathlib.Path(\"~/mnt/bandicoot\").resolve(), root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091582c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "data_dict = {\n",
    "    \"sc\": {\n",
    "        \"input\": pathlib.Path(\n",
    "            f\"{profile_base_dir}/data/all_patient_profiles/sc_profiles.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"output\": pathlib.Path(f\"{root_dir}/5.EDA/results/sc_umap.parquet\").resolve(),\n",
    "    },\n",
    "    \"sc_fs\": {\n",
    "        \"input\": pathlib.Path(\n",
    "            f\"{profile_base_dir}/data/all_patient_profiles/sc_fs_profiles.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"output\": pathlib.Path(\n",
    "            f\"{root_dir}/5.EDA/results/sc_fs_umap.parquet\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"sc_agg\": {\n",
    "        \"input\": pathlib.Path(\n",
    "            f\"{profile_base_dir}/data/all_patient_profiles/sc_agg_profiles.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"output\": pathlib.Path(\n",
    "            f\"{root_dir}/5.EDA/results/sc_agg_umap.parquet\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"organoid\": {\n",
    "        \"input\": pathlib.Path(\n",
    "            f\"{profile_base_dir}/data/all_patient_profiles/organoid_profiles.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"output\": pathlib.Path(\n",
    "            f\"{root_dir}/5.EDA/results/organoid_umap.parquet\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"organoid_fs\": {\n",
    "        \"input\": pathlib.Path(\n",
    "            f\"{profile_base_dir}/data/all_patient_profiles/organoid_fs_profiles.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"output\": pathlib.Path(\n",
    "            f\"{root_dir}/5.EDA/results/organoid_fs_umap.parquet\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"organoid_agg\": {\n",
    "        \"input\": pathlib.Path(\n",
    "            f\"{profile_base_dir}/data/all_patient_profiles/organoid_agg_profiles.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"output\": pathlib.Path(\n",
    "            f\"{root_dir}/5.EDA/results/organoid_agg_umap.parquet\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"sc_consensus\": {\n",
    "        \"input\": pathlib.Path(\n",
    "            f\"{profile_base_dir}/data/all_patient_profiles/sc_consensus_profiles.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"output\": pathlib.Path(\n",
    "            f\"{root_dir}/5.EDA/results/sc_consensus_umap.parquet\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"organoid_consensus\": {\n",
    "        \"input\": pathlib.Path(\n",
    "            f\"{profile_base_dir}/data/all_patient_profiles/organoid_consensus_profiles.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"output\": pathlib.Path(\n",
    "            f\"{root_dir}/5.EDA/results/organoid_consensus_umap.parquet\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "}\n",
    "\n",
    "data_dict[\"organoid\"][\"output\"].parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193b8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11623, 1931)\n",
      "Data shape after dropping NaN values: (11623, 1931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "~/miniforge3/envs/GFF_analysis/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mData shape after dropping NaN values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures_df.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Extract features and apply UMAP\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m umap_embedding = \u001b[43mumap_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Create a DataFrame with UMAP results\u001b[39;00m\n\u001b[32m     21\u001b[39m umap_df = pd.DataFrame(umap_embedding, columns=[\u001b[33m\"\u001b[39m\u001b[33mUMAP1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mUMAP2\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/GFF_analysis/lib/python3.12/site-packages/umap/umap_.py:2928\u001b[39m, in \u001b[36mUMAP.fit_transform\u001b[39m\u001b[34m(self, X, y, force_all_finite, **kwargs)\u001b[39m\n\u001b[32m   2890\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, force_all_finite=\u001b[38;5;28;01mTrue\u001b[39;00m, **kwargs):\n\u001b[32m   2891\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[32m   2892\u001b[39m \u001b[33;03m    output.\u001b[39;00m\n\u001b[32m   2893\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2926\u001b[39m \u001b[33;03m        Local radii of data points in the embedding (log-transformed).\u001b[39;00m\n\u001b[32m   2927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2928\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2929\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform_mode == \u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2930\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_dens:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/GFF_analysis/lib/python3.12/site-packages/umap/umap_.py:2372\u001b[39m, in \u001b[36mUMAP.fit\u001b[39m\u001b[34m(self, X, y, force_all_finite, **kwargs)\u001b[39m\n\u001b[32m   2368\u001b[39m     X = check_array(\n\u001b[32m   2369\u001b[39m         X, dtype=np.uint8, order=\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m, force_all_finite=force_all_finite\n\u001b[32m   2370\u001b[39m     )\n\u001b[32m   2371\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2372\u001b[39m     X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2375\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2376\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2378\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2379\u001b[39m \u001b[38;5;28mself\u001b[39m._raw_data = X\n\u001b[32m   2381\u001b[39m \u001b[38;5;66;03m# Handle all the optional arguments, setting default\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/GFF_analysis/lib/python3.12/site-packages/sklearn/utils/validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/GFF_analysis/lib/python3.12/site-packages/sklearn/utils/validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/GFF_analysis/lib/python3.12/site-packages/sklearn/utils/validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "umap_object = umap.UMAP(\n",
    "    n_neighbors=15, min_dist=0.1, metric=\"euclidean\", random_state=0\n",
    ")\n",
    "\n",
    "for dataset, paths in data_dict.items():\n",
    "    # Load the data\n",
    "    df = pd.read_parquet(data_dict[dataset][\"input\"])\n",
    "    metadata_columns = [x for x in df.columns if \"Metadata_\" in x]\n",
    "    metadata_df = df.copy()\n",
    "    metadata_df = df[metadata_columns]\n",
    "    features_df = df.drop(columns=metadata_columns, errors=\"ignore\")\n",
    "    print(features_df.shape)\n",
    "    # remove NaN values\n",
    "    # features_df = features_df.dropna(axis=0, how=\"any\")\n",
    "    print(f\"Data shape after dropping NaN values: {features_df.shape}\")\n",
    "    # Extract features and apply UMAP\n",
    "\n",
    "    umap_embedding = umap_object.fit_transform(features_df)\n",
    "\n",
    "    # Create a DataFrame with UMAP results\n",
    "    umap_df = pd.DataFrame(umap_embedding, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "    umap_df = pd.concat([metadata_df.reset_index(drop=True), umap_df], axis=1)\n",
    "    # Save the UMAP results\n",
    "    umap_df.to_parquet(data_dict[dataset][\"output\"], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181f22f",
   "metadata": {},
   "source": [
    "## Individual umaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72faea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_csv(\n",
    "    pathlib.Path(f\"{root_dir}/data/patient_IDs.txt\").resolve(strict=True),\n",
    "    header=None,\n",
    "    names=[\"patient\"],\n",
    ")[\"patient\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1fea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {}\n",
    "for patient in patients:\n",
    "    file_dict[patient] = {\n",
    "        \"fs\": {\n",
    "            \"sc\": {\n",
    "                \"input\": pathlib.Path(\n",
    "                    f\"{root_dir}/data/{patient}/image_based_profiles/4.feature_selected_profiles/sc_fs.parquet\"\n",
    "                ).resolve(strict=True),\n",
    "                \"output\": pathlib.Path(\n",
    "                    f\"{root_dir}/5.EDA/results/patient_results/{patient}_sc_fs_umap.parquet\"\n",
    "                ).resolve(),\n",
    "            },\n",
    "            \"organoid\": {\n",
    "                \"input\": pathlib.Path(\n",
    "                    f\"{root_dir}/data/{patient}/image_based_profiles/4.feature_selected_profiles/organoid_fs.parquet\"\n",
    "                ).resolve(strict=True),\n",
    "                \"output\": pathlib.Path(\n",
    "                    f\"{root_dir}/5.EDA/results/patient_results/{patient}_organoid_fs_umap.parquet\"\n",
    "                ).resolve(),\n",
    "            },\n",
    "        },\n",
    "        \"agg\": {\n",
    "            \"sc_parent_organoid_level\": {\n",
    "                \"input\": pathlib.Path(\n",
    "                    f\"{root_dir}/data/{patient}/image_based_profiles/5.aggregated_profiles/sc_agg_parent_organoid_level.parquet\"\n",
    "                ).resolve(strict=True),\n",
    "                \"output\": pathlib.Path(\n",
    "                    f\"{root_dir}/5.EDA/results/patient_results/{patient}_sc_agg_parent_organoid_level_umap.parquet\"\n",
    "                ).resolve(),\n",
    "            },\n",
    "            \"sc_well_level\": {\n",
    "                \"input\": pathlib.Path(\n",
    "                    f\"{root_dir}/data/{patient}/image_based_profiles/5.aggregated_profiles/sc_agg_well_level.parquet\"\n",
    "                ).resolve(strict=True),\n",
    "                \"output\": pathlib.Path(\n",
    "                    f\"{root_dir}/5.EDA/results/patient_results/{patient}_sc_agg_well_level_umap.parquet\"\n",
    "                ).resolve(),\n",
    "            },\n",
    "            \"sc_consensus\": {\n",
    "                \"input\": pathlib.Path(\n",
    "                    f\"{root_dir}/data/{patient}/image_based_profiles/5.aggregated_profiles/sc_consensus.parquet\"\n",
    "                ).resolve(strict=True),\n",
    "                \"output\": pathlib.Path(\n",
    "                    f\"{root_dir}/5.EDA/results/patient_results/{patient}_sc_consensus_umap.parquet\"\n",
    "                ).resolve(),\n",
    "            },\n",
    "            \"organoid_well_level\": {\n",
    "                \"input\": pathlib.Path(\n",
    "                    f\"{root_dir}/data/{patient}/image_based_profiles/5.aggregated_profiles/organoid_agg_well_level.parquet\"\n",
    "                ).resolve(strict=True),\n",
    "                \"output\": pathlib.Path(\n",
    "                    f\"{root_dir}/5.EDA/results/patient_results/{patient}_organoid_agg_well_level_umap.parquet\"\n",
    "                ).resolve(),\n",
    "            },\n",
    "            \"organoid_consensus\": {\n",
    "                \"input\": pathlib.Path(\n",
    "                    f\"{root_dir}/data/{patient}/image_based_profiles/5.aggregated_profiles/organoid_consensus.parquet\"\n",
    "                ).resolve(strict=True),\n",
    "                \"output\": pathlib.Path(\n",
    "                    f\"{root_dir}/5.EDA/results/patient_results/{patient}_organoid_consensus_umap.parquet\"\n",
    "                ).resolve(),\n",
    "            },\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a67f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in file_dict.keys():\n",
    "    for level in file_dict[patient].keys():\n",
    "        for profile_type in file_dict[patient][level].keys():\n",
    "            for dataset, paths in file_dict[patient][level][profile_type].items():\n",
    "                print(f\"Processing {patient} - {level} - {profile_type} - {dataset}\")\n",
    "                df = pd.read_parquet(file_dict[patient][level][profile_type][\"input\"])\n",
    "\n",
    "                metadata_df = df.copy()\n",
    "                metadata_subset = []\n",
    "                for col in metadata_columns:\n",
    "                    if col in df.columns:\n",
    "                        metadata_subset.append(col)\n",
    "\n",
    "                metadata_df = df[metadata_subset]\n",
    "                features_df = df.drop(columns=metadata_columns, errors=\"ignore\")\n",
    "                print(features_df.shape)\n",
    "                # remove NaN values\n",
    "                features_df = features_df.dropna(axis=0, how=\"any\")\n",
    "                print(f\"Data shape after dropping NaN values: {features_df.shape}\")\n",
    "                # Extract features and apply UMAP\n",
    "\n",
    "                umap_embedding = umap_object.fit_transform(features_df)\n",
    "\n",
    "                # Create a DataFrame with UMAP results\n",
    "                umap_df = pd.DataFrame(umap_embedding, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "                umap_df = pd.concat(\n",
    "                    [metadata_df.reset_index(drop=True), umap_df], axis=1\n",
    "                )\n",
    "                # Save the UMAP results\n",
    "                file_dict[patient][level][profile_type][\"output\"].parent.mkdir(\n",
    "                    parents=True, exist_ok=True\n",
    "                )\n",
    "                umap_df.to_parquet(\n",
    "                    file_dict[patient][level][profile_type][\"output\"], index=False\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GFF_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
